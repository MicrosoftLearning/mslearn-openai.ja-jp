---
lab:
  title: Azure OpenAI Service を使用して検索拡張生成 (RAG) を実装する
---

# Azure OpenAI Service を使用して検索拡張生成 (RAG) を実装する

Azure OpenAI Service を使用すると、基になる LLM のインテリジェンスで独自のデータを使用できます。 独自のデータのみを関連トピックに使用するようにモデルを制限したり、事前トレーニング済みモデルの結果とブレンドしたりすることができます。

この演習のシナリオで、あなたは Margie's Travel Agency で働くソフトウェア開発者の役割を演じます。 生成 AI を使ってコーディング タスクをより簡単かつ効率的にする方法について説明します。 この演習で使われる手法は、他のコード ファイル、プログラミング言語、ユース ケースに適用できます。

この演習には約 **20** 分かかります。

## Azure OpenAI リソースをプロビジョニングする

まだ持っていない場合は、Azure サブスクリプションで Azure OpenAI リソースをプロビジョニングします。

1. **Azure portal** (`https://portal.azure.com`) にサインインします。
2. 次の設定で **Azure OpenAI** リソースを作成します。
    - **[サブスクリプション]**: "Azure OpenAI Service へのアクセスが承認されている Azure サブスクリプションを選びます"**
    - **[リソース グループ]**: *リソース グループを作成または選択します*
    - **[リージョン]**: *以下のいずれかのリージョンから**ランダム**に選択する*\*
        - オーストラリア東部
        - カナダ東部
        - 米国東部
        - 米国東部 2
        - フランス中部
        - 東日本
        - 米国中北部
        - スウェーデン中部
        - スイス北部
        - 英国南部
    - **[名前]**: "*希望する一意の名前*"
    - **価格レベル**: Standard S0

    > \* Azure OpenAI リソースは、リージョンのクォータによって制限されます。 一覧表示されているリージョンには、この演習で使用されるモデル タイプの既定のクォータが含まれています。 リージョンをランダムに選択することで、サブスクリプションを他のユーザーと共有しているシナリオで、1 つのリージョンがクォータ制限に達するリスクが軽減されます。 演習の後半でクォータ制限に達した場合は、別のリージョンに別のリソースを作成する必要が生じる可能性があります。

3. デプロイが完了するまで待ちます。 次に、Azure portal でデプロイされた Azure OpenAI リソースに移動します。

## モデルをデプロイする

Azure OpenAI には、モデルのデプロイ、管理、探索に使用できる **Azure OpenAI Studio** という名前の Web ベースのポータルが用意されています。 Azure OpenAI Studio を使用してモデルをデプロイすることで、Azure OpenAI の探索を開始します。

1. Azure OpenAI リソースの **[概要]** ページで、 **[Azure OpenAI Studio に移動する]** ボタンを使用して、新しいブラウザー タブで Azure OpenAI Studio を開きます。
2. Azure OpenAI Studio の [**デプロイ**] ページで、既存のモデルのデプロイを表示します。 まだデプロイがない場合は、次の設定で **gpt-35-turbo-16k** モデルの新しいデプロイを作成します。
    - **デプロイの名前**: *任意の一意の名前*
    - **モデル**: gpt-35-turbo-16k "(16k モデルが使用できない場合は、gpt-35-turbo を選びます)"**
    - **モデル バージョン**: 既定値に自動更新
    - **デプロイの種類**:Standard
    - **1 分あたりのトークンのレート制限**: 5K\*
    - **コンテンツ フィルター**: 既定
    - **動的クォータを有効にする**: 有効

    > \* この演習は、1 分あたり 5,000 トークンのレート制限内で余裕を持って完了できます。またこの制限によって、同じサブスクリプションを使用する他のユーザーのために容量を残すこともできます。

## 独自のデータを追加せずに、通常のチャット動作を確認する

Azure OpenAI を独自のデータに接続する前に、まず、基本モデルが、グラウンディング データなしでクエリに応答する方法を確認しましょう。

1. **Azure OpenAI Studio** (`https://oai.azure.com`) の **[プレイグラウンド]** セクションで、**[チャット]** ページを選びます。 **[チャット]** プレイグラウンド ページは、次の 3 つのメイン セクションで構成されています。
    - **設定** - モデルの応答のコンテキストを設定するために使われます。
    - **チャット セッション** - チャット メッセージを送信し、応答を表示するために使われます。
    - **構成** - モデル デプロイの設定を構成するために使われます。
2. **[構成]** セクションで、モデル デプロイが選ばれていることを確認します。
3. **[設定]** 領域で、既定のシステム メッセージ テンプレートを選び、チャット セッションのコンテキストを設定します。 既定のシステム メッセージは、"あなたはユーザーが情報を見つけるのを助ける AI アシスタントです" です。**
4. **チャット セッション**で次のクエリを送信し、応答を確認します。

    ```prompt
    I'd like to take a trip to New York. Where should I stay?
    ```

    ```prompt
    What are some facts about New York?
    ```

    根拠となるデータに含める他の場所 (ロンドン、サンフランシスコなど) についても、観光や滞在場所に関する同様の質問を試します。 地域や近隣地域に関する完全な応答、およびその都市に関する一般的な事実が返されるでしょう。

## チャット プレイグラウンドで独自のデータを接続する

次に、*Margie's Travel* という架空の旅行代理店会社のデータを追加します。 次に、Margie's Travel のパンフレットをグラウンディング データとして使ったときに、Azure OpenAI モデルがどのように応答するかを確認します。

1. 新しいブラウザー タブで、`https://aka.ms/own-data-brochures` からパンフレット データのアーカイブをダウンロードします。 パンフレットを PC 上のフォルダーに展開します。
1. Azure OpenAI Studio の **[チャット]** プレイグラウンドの **[設定]** セクションで、**[データの追加]** を選びます。
1. **[データ ソースの追加]** を選び、**[ファイルのアップロード]** を選びます。
1. ストレージ アカウントと Azure AI 検索リソースを作成する必要があります。 ストレージ リソースのドロップダウンで、 **[新しい Azure BLOB ストレージ リソースの作成]** を選択し、次の設定でストレージ アカウントを作成します。 指定されていない設定はすべて、既定値のままにします。

    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **[リソース グループ]**: "Azure OpenAI リソースと同じリソース グループを選びます"**
    - **ストレージ アカウント名**: *一意の名前を入力します*
    - **[リージョン]**: "Azure OpenAI リソースと同じリージョンを選びます"**
    - **冗長**: ローカル冗長ストレージ (LRS)

1. ストレージ アカウント リソースが作成されている間に、Azure OpenAI Studio に戻り、次の設定で **[新しい Azure AI 検索リソースの作成]** を選びます。 指定されていない設定はすべて、既定値のままにします。

    - **[サブスクリプション]**:"*ご自身の Azure サブスクリプション*"
    - **[リソース グループ]**: "Azure OpenAI リソースと同じリソース グループを選びます"**
    - **サービス名**: *一意の名前を入力します*
    - **[場所]**: "Azure OpenAI リソースと同じ場所を選びます"**
    - **価格レベル**: Basic

1. 検索リソースがデプロイされるまで待ってから、Azure AI Studio に戻ります。
1. **[データの追加]** で、データ ソースに関する次の値を入力し、 **[次へ]** を選択します。

    - **データ ソースの選択**: ファイルのアップロード
    - **サブスクリプション**:お使いの Azure サブスクリプション
    - **Azure Blob Storage リソースを選びます**。"**[更新]** ボタンを使って一覧を再作成し、作成したストレージ リソースを選びます"**
        - プロンプトが表示されたら CORS を有効にします
    - **Azure AI 検索リソースを選びます**。"**[更新]** ボタンを使って一覧を再作成し、作成した検索リソースを選びます"**
    - **インデックス名を入力します**: `margiestravel`
    - **Add vector search to this search resource (この検索リソースにベクトル検索を追加する)** : オフ
    - **I acknowledge that connecting to an Azure AI Search account will incur usage to my account (アカウントに接続すると、自分のアカウントに対して使用料が発生することに同意します)** : オン

1. **[ファイルのアップロード]** ページで、ダウンロードした PDF をアップロードし、 **[次へ]** を選択します。
1. **[データ管理]** ページで、ドロップダウンから **[キーワード]** の検索の種類を選択し、 **[次へ]** を選択します。
1. **[データ接続]** ページで **[API キー]** を選択します。
1. **[レビューと完了]** ページで **[保存して閉じる]** を選択すると、データが追加されます。 これには数分かかる場合があります。その間、ウィンドウを開いたままにしておく必要があります。 完了すると、**[設定]** セクションで指定したデータ ソース、検索リソース、インデックスが表示されます。

    > **ヒント**: 場合によっては、新しい検索インデックスと Azure OpenAI Studio 間の接続に時間がかかりすぎることがあります。 数分待っても接続できない場合は、Azure portal で AI 検索リソースを確認します。 完成したインデックスが表示された場合は、Azure OpenAI Studio でデータ接続を切断し、Azure AI 検索データ ソースを指定して新しいインデックスを選ぶことで接続を再追加できます。

## 独自のデータを根拠とするモデルとチャットする

データを追加したので、前と同じ質問をして、応答がどのように異なるかを確認します。

```prompt
I'd like to take a trip to New York. Where should I stay?
```

```prompt
What are some facts about New York?
```

特定のホテルに関する詳細や Margie's Travel への言及、提供された情報の出所への言及など、今度の応答はまったく異なることに気付くでしょう。 応答で一覧表示されている PDF 形式のリファレンスを開くと、ホテルが、モデルによって提示されたものと同じであることがわかります。

根拠となるデータに含まれる他の都市 (ドバイ、ラスベガス、ロンドン、サンフランシスコ) についても質問してみましょう。

> **注**: **[Add your data](独自のデータの追加)** はまだプレビュー段階であり、この機能は必ずしも期待どおりに動作するとは限りません。たとえば、根拠となるデータに含まれていない都市については、提供される参考情報が正しくない場合があります。

## アプリを独自のデータに接続する

次に、アプリを接続して独自のデータを使う方法を見てみましょう。

### Visual Studio Code でアプリを開発する準備をする

次に、Azure OpenAI Service SDK を使うアプリで独自のデータを使う方法を見てみましょう。 Visual Studio Code を使用してアプリを開発します。 アプリのコード ファイルは、GitHub リポジトリで提供されています。

> **ヒント**: 既に **mslearn-openai** リポジトリをクローンしている場合は、Visual Studio Code で開きます。 それ以外の場合は、次の手順に従って開発環境に複製します。

1. Visual Studio Code を起動します。
2. パレットを開き (SHIFT+CTRL+P)、**Git:Clone** コマンドを実行して、`https://github.com/MicrosoftLearning/mslearn-openai` リポジトリをローカル フォルダーに複製します (どのフォルダーでも問題ありません)。
3. リポジトリを複製したら、Visual Studio Code でフォルダーを開きます。

    > **注**:Visual Studio Code に、開いているコードを信頼するかどうかを求めるポップアップ メッセージが表示された場合は、ポップアップの **[はい、作成者を信頼します]** オプションをクリックします。

4. リポジトリ内の C# コード プロジェクトをサポートするために追加のファイルがインストールされるまで待ちます。

    > **注**: ビルドとデバッグに必要なアセットを追加するように求めるプロンプトが表示された場合は、**[今はしない]** を選択します。

## アプリケーションを構成する

C# と Python の両方のアプリケーションが用意されており、どちらのアプリも同じ機能を備えています。 まず、Azure OpenAI リソースの使用を有効にするために、アプリケーションの主要な部分をいくつか完成させます。

1. Visual Studio Code の **[エクスプローラー]** ペインで、**Labfiles/06-use-own-data** フォルダーを参照し、言語の設定に応じて、**CSharp** または **Python** フォルダーを展開します。 各フォルダーには、Azure OpenAI 機能を統合するアプリの言語固有のファイルが含まれています。
2. コード ファイルが含まれている **CSharp** または **Python** フォルダーを右クリックし、統合ターミナルを開きます。 次に、言語設定に応じて適切なコマンドを実行して、Azure OpenAI SDK パッケージをインストールします。

    **C#:**

    ```
    dotnet add package Azure.AI.OpenAI --version 1.0.0-beta.14
    ```

    **Python**:

    ```
    pip install openai==1.13.3
    ```

3. **[エクスプローラー]** ペインの **CSharp** または **Python** フォルダーで、使用する言語の構成ファイルを開きます

    - **C#**: appsettings.json
    - **Python**: .env
    
4. 次を含めて構成値を更新します。
    - 作成した Azure OpenAI リソースの**エンドポイント**と**キー** (Azure Portal の Azure OpenAI リソースの [**キーとエンドポイント**] ページで使用できます)
    - モデル デプロイに指定した**デプロイ名** (Azure OpenAI Studio の **[デプロイ]** ページで確認できます)。
    - 検索サービスのエンドポイント (Azure Portal の検索リソースの概要ページの **URL** 値)。
    - 検索リソースの**キー** (Azure Portal の検索リソースの [**キー**] ページで使用できます。管理者キーのいずれかを使用できます)。
    - 検索インデックスの名前 (`margiestravel` になります)。
1. 構成ファイルを保存します。

### Azure OpenAI サービスを使うコードを追加する

これで、Azure OpenAI SDK を使って、デプロイされたモデルを使う準備が整いました。

1. **[エクスプローラー]** ペインの **CSharp** または **Python** フォルダーで、使う言語のコード ファイルを開き、コメント "***Configure your data source***" を、Azure OpenAI SDK ライブラリを追加するコードに置き換えます。

    **C#**: ownData.cs

    ```csharp
    // Configure your data source
    AzureSearchChatExtensionConfiguration ownDataConfig = new()
    {
            SearchEndpoint = new Uri(azureSearchEndpoint),
            Authentication = new OnYourDataApiKeyAuthenticationOptions(azureSearchKey),
            IndexName = azureSearchIndex
    };
    ```

    **Python**: ownData.py

    ```python
    # Configure your data source
    extension_config = dict(dataSources = [  
            { 
                "type": "AzureCognitiveSearch", 
                "parameters": { 
                    "endpoint":azure_search_endpoint, 
                    "key": azure_search_key, 
                    "indexName": azure_search_index,
                }
            }]
        )
    ```

2. コードの残りの部分を確認して、データ ソース設定に関する情報の提供に使われる要求本文内での "拡張機能" の使用に注目してください。**

3. コード ファイルに加えた変更を保存します。

## アプリケーションを実行する

アプリが構成されたので、それを実行してモデルに要求を送信し、応答を確認します。 異なるオプションの間で違いがあるのはプロンプトの内容のみであり、他のすべてのパラメーター (トークン数や温度など) は要求ごとに変わりがないことがわかります。

1. 対話型ターミナル ペインで、フォルダー コンテキストが優先言語のフォルダーであることを確認します。 その後、次のコマンドを入力してアプリケーションを作成します。

    - **C#** : `dotnet run`
    - **Python**: `python ownData.py`

    > **ヒント**: ターミナル ツールバーの **最大化パネル サイズ** (**^**) アイコンを使用すると、コンソール テキストをさらに表示できます。

2. プロンプト `Tell me about London` に対する応答を確認します。これには、回答だけでなく、検索サービスから取得したプロンプトのグラウンディングに使われるデータの詳細が含まれているはずです。

    > **ヒント**: 検索インデックスからの引用を表示する場合は、コード ファイルの先頭近くにある変数 ***show citations*** を **true** に設定します。

## クリーンアップ

Azure OpenAI リソースでの作業が完了したら、**Azure portal** (`https://portal.azure.com`) でリソースを忘れずに削除します。 これには、ストレージ アカウントと検索リソースも含まれます。これらによって比較的多額のコストが発生する可能性があるため、必ず削除してください。
